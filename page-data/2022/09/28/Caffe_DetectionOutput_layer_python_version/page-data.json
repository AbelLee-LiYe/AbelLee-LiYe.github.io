{"componentChunkName":"component---gatsby-theme-replica-src-templates-post-tsx","path":"/2022/09/28/Caffe_DetectionOutput_layer_python_version/","result":{"data":{"post":{"body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Caffe DetectionOutput Layer Python Version\",\n  \"date\": \"2022-09-28T16:28:00.000Z\",\n  \"tags\": [\"Algorithm\"],\n  \"category\": \"Algorithm\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"import cv2\\nimport caffe\\nimport numpy as np\\nimport math\\nimport functools\\nimport time\\n\\n\\nclass NormalizedBBox:\\n    def __init__(self, xmin, ymin, xmax, ymax):\\n        self.xmin = xmin\\n        self.ymin = ymin\\n        self.xmax = xmax\\n        self.ymax = ymax\\n        self.size = 0\\n\\n\\ndef BBoxSize(\\n        bbox,  # type: NormalizedBBox\\n        normalized=True):\\n    if bbox.xmax < bbox.xmin or bbox.ymax < bbox.ymin:\\n        return 0\\n\\n    width = bbox.xmax - bbox.xmin\\n    height = bbox.ymax - bbox.ymin\\n    if normalized:\\n        return width * height\\n    else:\\n        return (width + 1) * (height + 1)\\n\\n\\ndef ClipBBox(\\n        bbox  # type: NormalizedBBox\\n):\\n    bbox.xmin = max(min(bbox.xmin, 1.), 0.)\\n    bbox.ymin = max(min(bbox.ymin, 1.), 0.)\\n    bbox.xmax = max(min(bbox.xmax, 1.), 0.)\\n    bbox.ymax = max(min(bbox.ymax, 1.), 0.)\\n    bbox.size = BBoxSize(bbox)\\n    # TODO bbox.difficult = difficult\\n\\n\\ndef DecodeBBox(prior_bbox, prior_variance, code_type, variance_encoded_in_target, clip_bbox, bbox, decode_bbox):\\n    if code_type == 0:\\n        if variance_encoded_in_target:\\n            decode_bbox.xmin = prior_bbox.xmin + bbox.xmin\\n            decode_bbox.ymin = prior_bbox.ymin + bbox.ymin\\n            decode_bbox.xmax = prior_bbox.xmax + bbox.xmax\\n            decode_bbox.ymax = prior_bbox.ymax + bbox.ymax\\n        else:\\n            decode_bbox.xmin = prior_bbox.xmin + float(prior_variance[0]) * bbox.xmin\\n            decode_bbox.ymin = prior_bbox.ymin + float(prior_variance[1]) * bbox.ymin\\n            decode_bbox.xmax = prior_bbox.xmax + float(prior_variance[2]) * bbox.xmax\\n            decode_bbox.ymax = prior_bbox.ymax + float(prior_variance[3]) * bbox.ymax\\n\\n    elif code_type == 1:\\n        prior_width = prior_bbox.xmax - prior_bbox.xmin\\n        assert prior_width > 0\\n        prior_height = prior_bbox.ymax - prior_bbox.ymin\\n        assert prior_height > 0\\n        prior_center_x = (prior_bbox.xmin + prior_bbox.xmax) / 2.\\n        prior_center_y = (prior_bbox.ymin + prior_bbox.ymax) / 2.\\n\\n        if variance_encoded_in_target:\\n            decode_bbox_center_x = bbox.xmin * prior_width + prior_center_x\\n            decode_bbox_center_y = bbox.ymin * prior_height + prior_center_y\\n            decode_bbox_width = math.exp(bbox.xmax) * prior_width\\n            decode_bbox_height = math.exp(bbox.ymax) * prior_height\\n        else:\\n            decode_bbox_center_x = float(prior_variance[0]) * bbox.xmin * prior_width + prior_center_x\\n            decode_bbox_center_y = float(prior_variance[1]) * bbox.ymin * prior_height + prior_center_y\\n            decode_bbox_width = math.exp(float(prior_variance[2]) * bbox.xmax) * prior_width\\n            decode_bbox_height = math.exp(float(prior_variance[3]) * bbox.ymax) * prior_height\\n\\n        decode_bbox.xmin = decode_bbox_center_x - decode_bbox_width / 2.\\n        decode_bbox.ymin = decode_bbox_center_y - decode_bbox_height / 2.\\n        decode_bbox.xmax = decode_bbox_center_x + decode_bbox_width / 2.\\n        decode_bbox.ymax = decode_bbox_center_y + decode_bbox_height / 2.\\n\\n    elif code_type == 2:\\n        prior_width = prior_bbox.xmax - prior_bbox.xmin\\n        assert prior_width > 0\\n        prior_height = prior_bbox.ymax - prior_bbox.ymin\\n        assert prior_height > 0\\n        if variance_encoded_in_target:\\n            decode_bbox.xmin = prior_bbox.xmin + bbox.xmin * prior_width\\n            decode_bbox.ymin = prior_bbox.ymin + bbox.ymin * prior_height\\n            decode_bbox.xmax = prior_bbox.xmax + bbox.xmax * prior_width\\n            decode_bbox.ymax = prior_bbox.ymax + bbox.ymax * prior_height\\n        else:\\n            decode_bbox.xmin = prior_bbox.xmin + float(prior_variance[0]) * bbox.xmin * prior_width\\n            decode_bbox.ymin = prior_bbox.ymin + float(prior_variance[1]) * bbox.ymin * prior_height\\n            decode_bbox.xmax = prior_bbox.xmax + float(prior_variance[2]) * bbox.xmax * prior_width\\n            decode_bbox.ymax = prior_bbox.ymax + float(prior_variance[3]) * bbox.ymax * prior_height\\n\\n    else:\\n        print(\\\"Unknown LocLossType.\\\")\\n\\n    decode_bbox.size = BBoxSize(decode_bbox)\\n    if clip_bbox:\\n        ClipBBox(decode_bbox)\\n\\n\\ndef first_compare(a, b):\\n    if a[0] > b[0]:\\n        return 1\\n    elif a[0] < b[0]:\\n        return -1\\n    else:\\n        return 0\\n\\n\\ndef GetMaxScoreIndex(scores, threshold, top_k):\\n    score_index_vec = []\\n    for n in range(len(scores)):\\n        if scores[n] > threshold:\\n            score_index_vec.append((scores[n], n))\\n\\n    score_index_vec.sort(key=functools.cmp_to_key(first_compare), reverse=True)\\n    if -1 < top_k < len(score_index_vec):\\n        score_index_vec = score_index_vec[: top_k]\\n    return score_index_vec\\n\\n\\ndef IntersectBBox(bbox1, bbox2, intersect_bbox):\\n    if bbox2.xmin > bbox1.xmax or bbox2.xmax < bbox1.xmin or bbox2.ymin > bbox1.ymax or bbox2.ymax < bbox1.ymin:\\n        intersect_bbox.xmin = 0\\n        intersect_bbox.ymin = 0\\n        intersect_bbox.xmax = 0\\n        intersect_bbox.ymax = 0\\n    else:\\n        intersect_bbox.xmin = max(bbox1.xmin, bbox2.xmin)\\n        intersect_bbox.ymin = max(bbox1.ymin, bbox2.ymin)\\n        intersect_bbox.xmax = min(bbox1.xmax, bbox2.xmax)\\n        intersect_bbox.ymax = min(bbox1.ymax, bbox2.ymax)\\n\\n\\ndef JaccardOverlap(bbox1, bbox2, normalized=True):\\n    intersect_bbox = NormalizedBBox(0., 0., 0., 0.)\\n    IntersectBBox(bbox1, bbox2, intersect_bbox)\\n    if normalized:\\n        intersect_width = intersect_bbox.xmax - intersect_bbox.xmin\\n        intersect_height = intersect_bbox.ymax - intersect_bbox.ymin\\n    else:\\n        intersect_width = intersect_bbox.xmax - intersect_bbox.xmin + 1.\\n        intersect_height = intersect_bbox.ymax - intersect_bbox.ymin + 1.\\n    if intersect_width > 0 and intersect_height > 0:\\n        intersect_size = intersect_width * intersect_height\\n        bbox1_size = BBoxSize(bbox1)\\n        bbox2_size = BBoxSize(bbox2)\\n        return intersect_size / (bbox1_size + bbox2_size - intersect_size)\\n    else:\\n        return 0\\n\\n\\ndef ApplyNMSFast(\\n        bboxes,\\n        scores,\\n        score_threshold,\\n        nms_threshold,\\n        eta,\\n        _top_k,\\n        indices):\\n    assert len(bboxes) == len(scores)\\n    score_index_vec = GetMaxScoreIndex(scores, score_threshold, _top_k)\\n    adaptive_threshold = nms_threshold\\n\\n    for score_index in score_index_vec:\\n        idx = score_index[1]\\n        keep = True\\n        for k in range(len(indices)):\\n            if keep:\\n                kept_idx = indices[k]\\n                overlap = JaccardOverlap(bboxes[idx], bboxes[kept_idx])\\n                keep = overlap <= adaptive_threshold\\n            else:\\n                break\\n        if keep:\\n            indices.append(idx)\\n        if keep and eta < 1 and adaptive_threshold > 0.5:\\n            adaptive_threshold = eta\\n\\n\\ndef DecodeBBoxes(prior_bboxes, prior_variances, code_type, variance_encoded_in_target, clip_bbox, bboxes,\\n                 decode_bboxes):\\n    assert len(prior_bboxes) == len(prior_variances)\\n    assert len(prior_bboxes) == len(bboxes)\\n    num_bboxes = len(prior_bboxes)\\n    if num_bboxes >= 1:\\n        assert len(prior_variances[0]) == 4\\n    for n in range(num_bboxes):\\n        decode_bbox = NormalizedBBox(.0, .0, .0, .0)\\n        DecodeBBox(prior_bboxes[n], prior_variances[n], code_type,\\n                   variance_encoded_in_target, clip_bbox, bboxes[n], decode_bbox)\\n        decode_bboxes.append(decode_bbox)\\n\\n\\ndef detection_out(mreshape_loc, mbox_conf_flatten, reshape_priorbox):\\n    background_label_id_ = 0\\n    confidence_threshold_ = 0.3\\n    keep_top_k_ = 200\\n    nms_threshold_ = 0.45\\n    top_k_ = 400\\n    eta_ = 1.0\\n    num_classes_ = 81\\n    share_location_ = True\\n    code_type_ = 1  # 0: CORNER, 1:CENTER_SIZE, 2:CORNER_SIZE\\n    variance_encoded_in_target_ = False\\n\\n    confidence_threshold_ = confidence_threshold_ if confidence_threshold_ else 3.40282347e+38\\n    top_k_ = top_k_ if top_k_ else -1\\n    num_priors_ = int(reshape_priorbox.shape[2] / 4)\\n    num_loc_classes_ = 1 if share_location_ else num_classes_\\n\\n    num = mreshape_loc.shape[0]\\n\\n    # Retrieve all location predictions.\\n    loc_data = mreshape_loc.flatten()\\n    num_preds_per_class = num_priors_\\n    num_loc_classes = num_loc_classes_\\n    share_location = share_location_\\n\\n    # GetLocPredictions Retrieve all location predictions.\\n    all_loc_preds = []\\n    for n in range(num):\\n        label_bbox = {}\\n        offset = num_preds_per_class * num_loc_classes * 4 * n\\n        for p in range(num_preds_per_class):\\n            start_idx = offset + p * num_loc_classes * 4\\n            for c in range(num_loc_classes):\\n                label = -1 if share_location else c\\n                if label not in label_bbox:\\n                    label_bbox[label] = {}\\n                label_bbox[label][p] = NormalizedBBox(\\n                    loc_data[start_idx + c * 4],\\n                    loc_data[start_idx + c * 4 + 1],\\n                    loc_data[start_idx + c * 4 + 2],\\n                    loc_data[start_idx + c * 4 + 3]\\n                )\\n        all_loc_preds.append(label_bbox)\\n\\n    # GetConfidenceScores Retrieve all confidences.\\n    all_conf_scores = []\\n    conf_data = mbox_conf_flatten.flatten()\\n    num_classes = num_classes_\\n\\n    for n in range(num):\\n        offset = num_preds_per_class * num_classes * n\\n        label_scores = {}\\n        for p in range(num_preds_per_class):\\n            start_idx = offset + p * num_classes\\n            for c in range(num_classes):\\n                if c not in label_scores:\\n                    label_scores[c] = []\\n                label_scores[c].append(conf_data[start_idx + c])\\n        all_conf_scores.append(label_scores)\\n\\n    # GetPriorBBoxes\\n    # Retrieve all prior bboxes. It is same within a batch since we assume all\\n    # images in a batch are of same dimension.\\n    prior_bboxes = []\\n    prior_variances = []\\n    prior_data = reshape_priorbox.flatten()\\n    num_priors = num_priors_\\n\\n    for n in range(num_priors):\\n        start_idx = n * 4\\n        bbox = NormalizedBBox(\\n            float(prior_data[start_idx]),\\n            float(prior_data[start_idx + 1]),\\n            float(prior_data[start_idx + 2]),\\n            float(prior_data[start_idx + 3]),\\n        )\\n\\n        bbox_size = BBoxSize(bbox)\\n        bbox.size = bbox_size\\n        prior_bboxes.append(bbox)\\n\\n    for n in range(num_priors):\\n        start_idx = (num_priors + n) * 4\\n        var = []\\n        for j in range(4):\\n            var.append(prior_data[start_idx + j])\\n        prior_variances.append(var)\\n\\n    # DecodeBBoxesAll\\n    all_decode_bboxes = []\\n    clip_bbox = False\\n\\n    all_loc_preds = all_loc_preds\\n    prior_bboxes = prior_bboxes\\n    prior_variances = prior_variances\\n    share_location = share_location_\\n    num_loc_classes = num_loc_classes_\\n    background_label_id = background_label_id_\\n    code_type = code_type_\\n    variance_encoded_in_target = variance_encoded_in_target_\\n    clip = clip_bbox\\n    assert (len(all_loc_preds) == num)\\n\\n    for n in range(num):\\n        decode_bboxes = {}\\n        for c in range(num_loc_classes):\\n            label = -1 if share_location else c\\n            if label == background_label_id:\\n                continue\\n            if label not in all_loc_preds[n]:\\n                print(\\\"Could not find location predictions for label \\\", label)\\n            decode_bboxes[label] = []\\n            label_loc_preds = all_loc_preds[n][label]\\n            DecodeBBoxes(prior_bboxes, prior_variances,\\n                         code_type, variance_encoded_in_target, clip,\\n                         label_loc_preds, decode_bboxes[label])\\n        all_decode_bboxes.append(decode_bboxes)\\n\\n    num_kept = 0\\n    all_indices = []\\n\\n    for n in range(num):\\n        decode_bboxes = all_decode_bboxes[n]\\n        conf_scores = all_conf_scores[n]\\n        num_det = 0\\n        indices = {}\\n        for c in range(num_classes_):\\n            if c == background_label_id_:\\n                continue\\n            if c not in conf_scores:\\n                print(\\\"Could not find confidence predictions for label \\\", c)\\n            if c not in indices:\\n                indices[c] = []\\n            scores = conf_scores[c]\\n            label = -1 if share_location_ else c\\n            if label not in decode_bboxes:\\n                print(\\\"Could not find location predictions for label \\\", label)\\n                continue\\n            bboxes = decode_bboxes[label]\\n            ApplyNMSFast(bboxes, scores, confidence_threshold_, nms_threshold_, eta_,\\n                         top_k_, indices[c])\\n            num_det += len(indices[c])\\n\\n        if keep_top_k_ > -1 and num_det < keep_top_k_:\\n            score_index_pairs = []\\n            for label in indices:\\n                label_indices = indices[label]\\n\\n                if label not in conf_scores:\\n                    print(\\\"Could not find location predictions for \\\", label)\\n                    continue\\n\\n                scores = conf_scores[label]\\n                for j in range(len(label_indices)):\\n                    idx = label_indices[j]\\n                    assert idx < len(scores)\\n                    score_index_pairs.append((scores[idx], (label, idx)))\\n\\n            score_index_pairs.sort(key=functools.cmp_to_key(first_compare), reverse=True)\\n\\n            score_index_pairs = score_index_pairs[: top_k_]\\n\\n            new_indices = {}\\n            for j in range(len(score_index_pairs)):\\n                label = score_index_pairs[j][1][0]\\n                idx = score_index_pairs[j][1][1]\\n                if label not in new_indices:\\n                    new_indices[label] = []\\n                new_indices[label].append(idx)\\n            all_indices.append(new_indices)\\n            num_kept += keep_top_k_\\n        else:\\n            all_indices.append(indices)\\n            num_kept += num_det\\n\\n    top_shape = [1, 1, num_kept, 7]\\n\\n    top_data = np.zeros(tuple(top_shape), dtype='float32')\\n    if num_kept == 0:\\n        print(\\\"Couldn't find any detections\\\")\\n        top_shape[2] = num\\n        top_data.reshape(tuple(top_shape))\\n        top_data.fill(-1)\\n        for n in range(num):\\n            top_data[0 + n * 7] = n\\n\\n    top_data_shape = top_data.shape\\n    top_data_flatten = top_data.flatten()\\n\\n    keep_count = 0\\n    count = 0\\n    for n in range(num):\\n        conf_scores = all_conf_scores[n]\\n        decode_bboxes = all_decode_bboxes[n]\\n        print(all_indices[n])\\n        for label in all_indices[n]:\\n            if label not in conf_scores:\\n                print(\\\"Could not find confidence predictions for \\\", label)\\n                continue\\n\\n            scores = conf_scores[label]\\n            loc_label = -1 if share_location_ else label\\n            if loc_label not in decode_bboxes:\\n                print(\\\"Could not find location predictions for \\\", loc_label)\\n                continue\\n\\n            bboxes = decode_bboxes[loc_label]\\n            indices = all_indices[n][label]\\n            keep_count += len(indices)\\n            for j in range(len(indices)):\\n                idx = indices[j]\\n                top_data_flatten[count * 7] = n\\n                top_data_flatten[count * 7 + 1] = label\\n                top_data_flatten[count * 7 + 2] = scores[idx]\\n                bbox = bboxes[idx]\\n                top_data_flatten[count * 7 + 3] = bbox.xmin\\n                top_data_flatten[count * 7 + 4] = bbox.ymin\\n                top_data_flatten[count * 7 + 5] = bbox.xmax\\n                top_data_flatten[count * 7 + 6] = bbox.ymax\\n                count += 1\\n\\n    top_data = top_data_flatten.reshape(top_data_shape)\\n\\n    return top_data, keep_count\\n\\n\\nif __name__ == '__main__':\\n    coco_net = caffe.Net('VGG_coco_SSD_512x512_iter_360000_without_detection_output.prototxt', # Cut Detection Output Layer\\n                         'VGG_coco_SSD_512x512_iter_360000_without_detection_output.caffemodel', caffe.TEST)\\n\\n    image_path = 'ssd.jpg'\\n    img = cv2.imread(image_path)\\n    resized_img = cv2.resize(img, (512, 512))\\n\\n    input_data = np.asarray(resized_img)\\n    input_data = input_data.transpose((2, 0, 1))\\n    input_data = input_data.reshape(1, 3, 512, 512)\\n    input_data = input_data.astype('float32')\\n\\n    blue_mean = 104.0\\n    green_mean = 117.0\\n    red_mean = 123.0\\n\\n    input_data[:, 0] -= blue_mean\\n    input_data[:, 1] -= green_mean\\n    input_data[:, 2] -= red_mean\\n\\n    coco_net.blobs['data'].data[...] = input_data\\n\\n    output = coco_net.forward()\\n    mreshape_loc = output['mreshape_loc']\\n    mbox_conf_flatten = output['mbox_conf_flatten']\\n    reshape_priorbox = output['reshape_priorbox']\\n\\n    start = time.time()\\n    detections, keep_count = detection_out(mreshape_loc, mbox_conf_flatten, reshape_priorbox)\\n    end = time.time()\\n    print(\\\"{:.2f}\\\".format(end - start))\\n\\n    # parse the output\\n    det_label = detections[0, 0, :, 1]\\n    det_conf = detections[0, 0, :, 2]\\n    det_xmin = detections[0, 0, :, 3]\\n    det_ymin = detections[0, 0, :, 4]\\n    det_xmax = detections[0, 0, :, 5]\\n    det_ymax = detections[0, 0, :, 6]\\n\\n    # get topN detections\\n    top_k = keep_count\\n    topk_indexes = det_conf.argsort()[::-1][:top_k]\\n\\n    top_conf = det_conf[topk_indexes]\\n    top_label_indexes = det_label[topk_indexes]\\n\\n    top_xmin = det_xmin[topk_indexes]\\n    top_ymin = det_ymin[topk_indexes]\\n    top_xmax = det_xmax[topk_indexes]\\n    top_ymax = det_ymax[topk_indexes]\\n\\n    for i in range(top_conf.shape[0]):\\n        label = int(round(det_label[i]))\\n        xmin = int(round(top_xmin[i] * 512.0))\\n        ymin = int(round(top_ymin[i] * 512.0))\\n        xmax = int(round(top_xmax[i] * 512.0))\\n        ymax = int(round(top_ymax[i] * 512.0))\\n        score = top_conf[i]\\n        print(label, score, xmin, ymin, xmax, ymax)\\n\\n        cv2.rectangle(resized_img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\\n    cv2.imwrite(\\\"ssd_out_cut.jpg\\\", resized_img)\\n\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"","fields":{"slug":"/2022/09/28/Caffe_DetectionOutput_layer_python_version/"},"frontmatter":{"date":"2022-09-28T16:28:00.000Z","title":"Caffe DetectionOutput Layer Python Version","tags":["Algorithm"],"category":"Algorithm"},"tableOfContents":{},"timeToRead":null}},"pageContext":{"postID":"100af763-97f0-530c-8c80-d1469a758ad5","numericId":26,"prevPost":{"slug":"/2022/05/05/何时使用引用参数/","title":"何时使用引用参数"},"nextPost":{"slug":"/2023/07/06/始于秋末的人生旅途/","title":"始于秋末的人生旅途"},"permalink":"https://www.abellee.cn/2022/09/28/Caffe_DetectionOutput_layer_python_version/"}},"staticQueryHashes":["2873555300","3400548236","822196256"]}